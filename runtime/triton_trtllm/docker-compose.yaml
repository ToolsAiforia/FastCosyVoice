services:
  trt:
    image: nvcr.io/nvidia/tensorrt-llm/release:0.20.0
    shm_size: '1gb'
    volumes:
      - ./run.sh:/app/tensorrt_llm/run.sh
      - ./scripts:/app/tensorrt_llm/scripts
      - ./CosyVoice2-0.5B:/app/tensorrt_llm/CosyVoice2-0.5B
      - ./cosyvoice2_llm:/app/tensorrt_llm/cosyvoice2_llm
      - ./trt_engines_bfloat16/:/app/tensorrt_llm/trt_engines_bfloat16/
    command:
      - bash
      - run.sh
      - "1"
      - "1"
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              device_ids: ['0']
              capabilities: [gpu]
  tts:
    build: .
    shm_size: '1gb'
    ports:
      - "8000:8000"
      - "8001:8001"
      - "8002:8002"
    environment:
      - PYTHONIOENCODING=utf-8
      - MODEL_ID=${MODEL_ID}
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              device_ids: ['0']
              capabilities: [gpu]
    command:
      - tritonserver
      - --model-repository=/model_repo
      - --cache-config=local,size=104857
